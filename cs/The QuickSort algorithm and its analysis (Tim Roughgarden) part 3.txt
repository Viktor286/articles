// Tim Roughgarden
// https://www.coursera.org/lecture/algorithms-divide-conquer/partitioning-around-a-pivot-xUd8B

The goal of this video is to provide more details about the implementation of the QuickSort algorithm and in particular, here we're going to drill down on the key Partition subroutine. Let me remind you what the job of the Partition subroutine is in the context of sorting an array.

So recall that key idea in QuickSort is to partition the input array around a pivot element. So this has two steps. First, you somehow choose a pivot element. And in this video, we're not going to worry about how you choose the pivot element. For concreteness, you might just want to think you pick the first element in the array to serve as your pivot.

So in this example array, the first element happens to be 3, so we can choose 3 as the pivot element. Now, there's a key rearrangement step. So you rearrange the array so that it has the following properties. Any entries that are to the left of the pivot element should be less than the pivot element. Whereas any entries, which are to the right of the pivot element, should be greater than the pivot element. So, for example, in the second version of the array, we see to the left of the 3 is the 2 and the 1. They're in reverse order, but that's okay. Both the 2 and the 1 are to the left of the 3, and they're both less than 3. And the five elements to the right of the 3, they're jumbled up, but they're all bigger than the pivot element. So, this is a legitimate rearrangement that satisfies the partitioning property.

And, again, recall that this definitely makes partial progress toward having a sorted array. The pivot element winds up in its rightful position. It winds up where it's supposed to be in the final sorted array, to the right of everything less than it, to the left of everything bigger than it. Moreover, we've correctly bucketed the other N-1 elements to the left and to the right of the pivot according to where they should wind up in the final sorted array. So that's the job, that the Partition subroutine is responsible for.

Now what's cool is we'll be able to implement this Partition subroutine in linear time. Even better, we'll be able to implement it so that all it does, really, is swaps in the array. That is, it works in-place. It needs no additional, essentially constant additional memory, to rearrange the array according to those properties. And then, as we saw on the high-level description of the QuickSort algorithm, what partitioning does is, it enables a divide-and-conquer approach. It reduces the problem size. After you've partitioned the array around the pivot, all you gotta do is recurse on the left side, recurse on the right side, and you're done.

So, what I owe you is this implementation. How do you actually satisfy the partitioning property, stuff to the left of the pivot is smaller than it, stuff to the right of the pivot is bigger than it, in linear time, and in-place. Well, first, let's observe that, if we didn't care about the in-place requirement, if we were happy to just allocate a second array and copy stuff over, it would actually be pretty easy to implement a Partition subroutine in linear time. That is, using O(N) extra memory, it's easy to partition around a pivot element in O(N) time. And as usual, you know, probably I should be more precise and write theta of N, are used in cases that would be the more accurate stronger statement, but I'm going to be sloppy and I'm just going to write the weaker but still correct statement, using Big-Oh, okay? So O(N) time using linear extra memory. So how would you do this? Well let me just sort of illustrate by example. I think you'll get the idea.

So let's go back to our running example of an input array. Well, if we're allowed to use linear extra space, we can just preallocate another array of length N. Then we can just do a simple scan through the input array, bucketing elements according to whether they are bigger than or less than the pivot. And, so for example, we can fill in the additional array both from the left and the right, using elements that are less than or bigger than the pivot respectively. So for example we start with the 8, we know that the 8 is bigger than the pivot, so you put that at the end of the output array. Then we get to the 2. The 2 is less than the pivot, so that should go on the left hand side of the output array. When you get to the 5, it should go on the right-hand side, and the 1 should go on the left-hand side, and so on. When we complete our scan through the input array, there'll be one hole left, and that's exactly where the pivot belongs, to the right of everything less than it, to the left of everything bigger than it.

So, what's really interesting, then, is to have an implementation of Partition, which is not merely linear time, but also uses essentially no additional space. It doesn't re-sort to this cop-out of pre-allocating an extra array of length N. So, let's turn to how that works. First, starting at a high-level, then filling in the details. So I'm gonna describe the Partition subroutine only for the case where the pivot is in fact the first element. But really this is without loss of generality. If, instead, you want to use some pivot from the middle of the array, you can just have a preprocessing step that swaps the first element of the array with the given pivot, and then run the subroutine that I'm about to describe, okay.

So with constant time preprocessing, the case of a general pivot reduces to the case when the pivot is the first element. So here's the high-level idea, and it's very cool. The idea is, we're gonna be able to able to get away with just a single linear scan of the input array. So in any given moment in this scan, there's just gonna be a single for-Loop, we'll be keeping track of both the part of the array we've looked at so far, and the part that we haven't looked at so far. So there's gonna be two groups, what we've seen, what we haven't seen. Then within the group we've seen, we're gonna have definitely split further, according to the elements that are less than the pivot and those that are bigger than the pivot.

So we're gonna leave the pivot element just hanging out in the first element of the array until the very end of the algorithm, when we correct its position with a swap. And at any given snapshot of this algorithm, we will have some stuff that we've already looked at, and some stuff that we haven't yet looked at in our linear scan. Of course, we have no idea what's up with the elements that we haven't looked at yet, who knows what they are, and whether they're bigger or less than the pivot. But, we're gonna implement the algorithm, so, among the stuff that we've already seen, it will be partitioned, in the sense that all elements less than the pivot come first, all elements bigger than the pivot come last. And, as usual, we don't care about the relative order, amongst elements less than the pivot, or amongst elements bigger than the pivot.

So summarizing, we do a single scan through the input array. And the trick will be to maintain the following invariant throughout the linear scan. But basically, everything we have looked at the input array is partitioned. Everything less than the pivot comes before everything bigger than the pivot. And, we wanna maintain that invariant, doing only constant work, and no additional storage, with each step of our linear scan. So, here's what I'm gonna do next. I'm gonna go through an example, and execute the Partition subroutine on a concrete array, the same input array we've been using as an example, thus far. Now, maybe it seems weird to give an example before I've actually given you the algorithm, before I've given you the code. But, doing it this way, I think you'll see the gist of what's going on in the example, and then when I present the code, it'll be very clear what's going on. Whereas, if I presented the code first, it may seem a little opaque when I first show you the algorithm. So, let's start with an example.

